Race classification from audio files will be using the Crowd-sourced Emotional Multimodal Actors Dataset (CREMA-D) downloaded from this repository: https://github.com/CheyneyComputerScience/CREMA-D. 

The model that was used to calculate the baseline uses Wav2Vec2 and the model code references this repository: https://github.com/m3hrdadfi/soxan

The metadata of each audio files is recorded in the table below: 
![image](https://user-images.githubusercontent.com/54903276/152845418-6b4b85cf-6973-4663-8101-75470dd042db.png)

The class distribution is as follows: 

![image](https://user-images.githubusercontent.com/54903276/152845505-2a46bc3e-765c-4f71-aedd-f2df60bc3481.png)

